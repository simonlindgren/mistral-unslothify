{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "384461e6",
   "metadata": {},
   "source": [
    "## mistral-unslothify\n",
    "\n",
    "Use ü§óhuggingface and Unsloth to finetune a Mistral pre-trained model on domain data.\n",
    "\n",
    "The aim here is to fine-tune the Mistral pre-trained model based on a set of text items that will attune it to perform more effectively on a specific domain. This means that we will be adapting the general capabilities of the model to better suit the needs and nuances of a particular field or area of expertise.\n",
    "\n",
    "Maybe surprisingly, in spite of a model such as for example Mistral 7B having seven billion parameters, the number of domain examples needed to fine-tune it can often be relatively small (see, for example, the widely cited paper on LLMs being ['few-shot learners'](https://arxiv.org/abs/2005.14165)). This is because large models like Mistral have a robust foundation of general language understanding, and the fine-tuning acts more like a focused nudge refining what the model already knows, rather than starting from scratch.\n",
    "\n",
    "As an example here, we have the file `domain.jsonl` with 500 text items to fine-tune the model for. All examples are about burgers üçîüçîüçî, so the model will become specifically tailored to text-based tasks around burgers.\n",
    "\n",
    "<img align=\"right\" src=\"icons/mistral.png\" width=\"60\" hspace=\"10\"> \n",
    "<img align=\"right\" src=\"icons/hf.png\" width=\"60\" hspace=\"10\"> \n",
    "<img align=\"right\" src=\"icons/unsloth.png\" width=\"150\" hspace=\"10\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457964cc",
   "metadata": {},
   "source": [
    "<hr>\n",
    "**NOTE**<br>\n",
    "This whole thing must be run on GPU. Either on a local machine with Nvidia/Cuda properly installed, on Google Colab with a free GPU runtime (even though they quickly run out), or any other cloud machine where the `!nvcc --version` cell below checks out ‚úÖ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a35a9b-a5c2-453f-a32b-0c5440856e06",
   "metadata": {
    "id": "14a35a9b-a5c2-453f-a32b-0c5440856e06"
   },
   "source": [
    "## 1. Setup and installations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ixHoUPsBD-5r",
   "metadata": {
    "id": "ixHoUPsBD-5r"
   },
   "source": [
    "Check to see that we have a GPU and Cuda driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce400ff-b908-4ff3-a5f6-338eafd1652c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ce400ff-b908-4ff3-a5f6-338eafd1652c",
    "outputId": "1c6eaf41-e797-4e21-9bbf-c2222f291270",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvcc\n"
     ]
    }
   ],
   "source": [
    "# check cuda version\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "zWDTUzXCE_h2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWDTUzXCE_h2",
    "outputId": "065a765c-f0e7-4049-8fab-0f0b18a8ce47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.3/1.8 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip -q\n",
    "\n",
    "# install the latest closest available cuda build\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h__s9sGYEtCT",
   "metadata": {
    "id": "h__s9sGYEtCT"
   },
   "source": [
    "Download `unsloth` from Github and install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad57af7f-73f0-4fb4-a02a-499139aac87e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad57af7f-73f0-4fb4-a02a-499139aac87e",
    "outputId": "22a84d66-a8a3-4d5c-98ab-16dc31d6a5a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'unsloth' already exists and is not an empty directory.\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/unslothai/unsloth.git\n",
    "!cd unsloth && pip install . -q\n",
    "#!pip show unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z18IhjcLFIA2",
   "metadata": {
    "id": "z18IhjcLFIA2"
   },
   "source": [
    "Install remaining needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2080de1d-6703-4ab4-a152-c9f643d1be50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2080de1d-6703-4ab4-a152-c9f643d1be50",
    "outputId": "bdc6499d-4a0b-4b93-a70a-96986dcfeb61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy -q\n",
    "!pip install bitsandbytes -q\n",
    "!pip install unsloth-zoo -q\n",
    "!pip install xformers -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a874d4-361c-4287-9d96-9d90267679fb",
   "metadata": {
    "id": "20a874d4-361c-4287-9d96-9d90267679fb"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bae7bd5-58c1-4c1c-bc6d-90a25dd53b9e",
   "metadata": {
    "id": "3bae7bd5-58c1-4c1c-bc6d-90a25dd53b9e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from unsloth import FastLanguageModel\n",
    "from unsloth import is_bfloat16_supported\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d4124-6541-427a-b3ea-68da09d598bc",
   "metadata": {
    "id": "d21d4124-6541-427a-b3ea-68da09d598bc"
   },
   "source": [
    "## 2. Download the pre-trained model and prepare for fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad65189-4168-44c9-9882-bfdf8436b992",
   "metadata": {
    "id": "1ad65189-4168-44c9-9882-bfdf8436b992"
   },
   "source": [
    "Download pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "F18LfOLGVbym",
   "metadata": {
    "id": "F18LfOLGVbym"
   },
   "outputs": [],
   "source": [
    "model_name = \"unsloth/mistral-7b-instruct-v0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2d9fa60-c2e9-46b7-895c-76391e486f5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2d9fa60-c2e9-46b7-895c-76391e486f5b",
    "outputId": "0397c2a9-0c3c-4490-fa53-320c1cf1a20c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.7: Fast Mistral patching. Transformers = 4.46.2.\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = 2048,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a8cac-c6b2-4b46-b093-7558103407a3",
   "metadata": {
    "id": "f41a8cac-c6b2-4b46-b093-7558103407a3"
   },
   "source": [
    "#### Add LoRA adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76d98987-c65d-4681-a6fe-9785cb14df68",
   "metadata": {
    "id": "76d98987-c65d-4681-a6fe-9785cb14df68"
   },
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    #use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b377d-a004-402e-97fe-760ca72206f7",
   "metadata": {
    "id": "877b377d-a004-402e-97fe-760ca72206f7"
   },
   "source": [
    "## 3. Prepare fine-tuning data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e917277-8992-4b00-9a06-ed57835aa42b",
   "metadata": {
    "id": "6e917277-8992-4b00-9a06-ed57835aa42b"
   },
   "outputs": [],
   "source": [
    "jsonl_file = \"domain.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gg9jVHfsVAze",
   "metadata": {
    "id": "gg9jVHfsVAze"
   },
   "source": [
    "Load and reformat the domain data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fDKhMvkiUTqM",
   "metadata": {
    "id": "fDKhMvkiUTqM"
   },
   "outputs": [],
   "source": [
    "# use the dataset loader by Huggingface and some formatting functions\n",
    "dataset = load_dataset(\"json\", data_files=jsonl_file, split=\"train\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def format_text(examples):\n",
    "    texts = [note + tokenizer.pad_token for note in examples[\"text\"]]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "dataset = dataset.map(format_text, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ScQDOp4VaVD",
   "metadata": {
    "id": "0ScQDOp4VaVD"
   },
   "source": [
    "Tokenize the domain data with the pre-trained model's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6lIjxLTbVTbp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "af854e58d42a431fa48535e8e8aa6644",
      "00ca831faf204bcf91fc78a5724cd8e6",
      "9c1aa1daf38e4aeb8d9858929be7ae14",
      "f30bcfdebbcc4391bb45b283ce0b48ce",
      "fff442eb8b5e4dbc9ddcf2f47b5bf414",
      "e51107af09b94c2d85b92ab8109d6af4",
      "1f9191103f414d559285cfed5927f528",
      "92a9b5b25a284609a138d4a9a209b08e",
      "2fb703591d6543ccaff0f98ace7f1e93",
      "a0074981ae6845208ae79c723866466a",
      "2c441204bcc94f10a9bdfc72db3d659d"
     ]
    },
    "id": "6lIjxLTbVTbp",
    "outputId": "77b865f1-0fe8-411b-d569-e9580bdb59a3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af854e58d42a431fa48535e8e8aa6644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the text\n",
    "def tokenize_texts(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_texts, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cWJbz5OqV9AE",
   "metadata": {
    "id": "cWJbz5OqV9AE"
   },
   "outputs": [],
   "source": [
    "# Remove unneeded columns and set format for PyTorch\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])  # Keep only tokenized columns\n",
    "tokenized_dataset.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OlT6-2JUYWPT",
   "metadata": {
    "id": "OlT6-2JUYWPT"
   },
   "source": [
    "## 4. Fine-tune the model\n",
    "\n",
    "We want the *training loss* to decrease. A loss value around 2-3 is reasonable, if it gets close to 1.0 or drop below the predictions will be highly confident, but also with some risk of overfitting, meaning that the model has learned the training data too well and may not perform as effectively on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "El6oh0aZkhgn",
   "metadata": {
    "id": "El6oh0aZkhgn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc5a9fa9-18c3-49ec-b0ce-5f45d38bef5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "cc5a9fa9-18c3-49ec-b0ce-5f45d38bef5a",
    "outputId": "eff0558d-4d9d-435a-aced-02d90ad43de4"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'trl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-39f749d203db>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFTTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munsloth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_bfloat16_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m trainer = SFTTrainer(\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'trl'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    max_seq_length=1024,\n",
    "    dataset_num_proc=2,\n",
    "    packing=False,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2, # ADJUST BASED ON AVAILABLE MEM\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=1, # NUMBER OF FULL PASSES THROUGH THE TRAINING DATASET\n",
    "        learning_rate=2e-4, # LOWER VALUES = SLOW BUT MORE STABLE LEARNING\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01, # APPLIES L2 REGULARIZATION TO AVOID OVERFITTING\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=1337,\n",
    "        output_dir=\"outputs\",\n",
    "        report_to=\"none\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer_stats = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00ca831faf204bcf91fc78a5724cd8e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e51107af09b94c2d85b92ab8109d6af4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1f9191103f414d559285cfed5927f528",
      "value": "Map:‚Äá100%"
     }
    },
    "1f9191103f414d559285cfed5927f528": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c441204bcc94f10a9bdfc72db3d659d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fb703591d6543ccaff0f98ace7f1e93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "92a9b5b25a284609a138d4a9a209b08e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c1aa1daf38e4aeb8d9858929be7ae14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92a9b5b25a284609a138d4a9a209b08e",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fb703591d6543ccaff0f98ace7f1e93",
      "value": 500
     }
    },
    "a0074981ae6845208ae79c723866466a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af854e58d42a431fa48535e8e8aa6644": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_00ca831faf204bcf91fc78a5724cd8e6",
       "IPY_MODEL_9c1aa1daf38e4aeb8d9858929be7ae14",
       "IPY_MODEL_f30bcfdebbcc4391bb45b283ce0b48ce"
      ],
      "layout": "IPY_MODEL_fff442eb8b5e4dbc9ddcf2f47b5bf414"
     }
    },
    "e51107af09b94c2d85b92ab8109d6af4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f30bcfdebbcc4391bb45b283ce0b48ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0074981ae6845208ae79c723866466a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2c441204bcc94f10a9bdfc72db3d659d",
      "value": "‚Äá500/500‚Äá[00:00&lt;00:00,‚Äá2067.96‚Äáexamples/s]"
     }
    },
    "fff442eb8b5e4dbc9ddcf2f47b5bf414": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
