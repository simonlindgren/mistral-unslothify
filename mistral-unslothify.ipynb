{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "384461e6",
   "metadata": {},
   "source": [
    "# mistral-unslothify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457964cc",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "This whole thing must be run on GPU. Either on a local machine with Nvidia/Cuda properly installed, on Google Colab with a free GPU runtime (even though they quickly run out), or any other cloud machine where the `!nvcc --version` cell below checks out âœ…."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a35a9b-a5c2-453f-a32b-0c5440856e06",
   "metadata": {
    "id": "14a35a9b-a5c2-453f-a32b-0c5440856e06"
   },
   "source": [
    "## 1. Setup and installations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ixHoUPsBD-5r",
   "metadata": {
    "id": "ixHoUPsBD-5r"
   },
   "source": [
    "Check to see that we have a GPU and Cuda driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce400ff-b908-4ff3-a5f6-338eafd1652c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ce400ff-b908-4ff3-a5f6-338eafd1652c",
    "outputId": "1c6eaf41-e797-4e21-9bbf-c2222f291270",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Fri_Jan__6_16:45:21_PST_2023\n",
      "Cuda compilation tools, release 12.0, V12.0.140\n",
      "Build cuda_12.0.r12.0/compiler.32267302_0\n"
     ]
    }
   ],
   "source": [
    "# check cuda version\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "zWDTUzXCE_h2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWDTUzXCE_h2",
    "outputId": "065a765c-f0e7-4049-8fab-0f0b18a8ce47"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip -q\n",
    "\n",
    "# install the latest closest available cuda build\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h__s9sGYEtCT",
   "metadata": {
    "id": "h__s9sGYEtCT"
   },
   "source": [
    "Download `unsloth` from Github and install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad57af7f-73f0-4fb4-a02a-499139aac87e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad57af7f-73f0-4fb4-a02a-499139aac87e",
    "outputId": "22a84d66-a8a3-4d5c-98ab-16dc31d6a5a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'unsloth' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/unslothai/unsloth.git\n",
    "!cd unsloth && pip install . -q\n",
    "#!pip show unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z18IhjcLFIA2",
   "metadata": {
    "id": "z18IhjcLFIA2"
   },
   "source": [
    "Install remaining needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2080de1d-6703-4ab4-a152-c9f643d1be50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2080de1d-6703-4ab4-a152-c9f643d1be50",
    "outputId": "bdc6499d-4a0b-4b93-a70a-96986dcfeb61"
   },
   "outputs": [],
   "source": [
    "!pip install numpy -q\n",
    "!pip install bitsandbytes -q\n",
    "!pip install unsloth-zoo -q\n",
    "!pip install xformers -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a874d4-361c-4287-9d96-9d90267679fb",
   "metadata": {
    "id": "20a874d4-361c-4287-9d96-9d90267679fb"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bae7bd5-58c1-4c1c-bc6d-90a25dd53b9e",
   "metadata": {
    "id": "3bae7bd5-58c1-4c1c-bc6d-90a25dd53b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from unsloth import FastLanguageModel\n",
    "from unsloth import is_bfloat16_supported\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02557af7-ebf0-4dbd-80bc-93ac098bc25a",
   "metadata": {},
   "source": [
    "## 2. Swedish Meatball Check with pre-trained Mistral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "023e2980-d0f3-4492-b2cf-719bf78e31f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af22e776c6f4bef940bb3c01b53bf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257774d0c1f24050adadb24409f33752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f787a4fe22b240b09bbc4e87b47b021d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b490aed0191424ba6f235a835335992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad7f394039f4502979c94594736759a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad60a67766c143ab855fb4a457a27a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5190aa02084cbeba5cad5479e44ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a0ce70a420466f807092193aa9d04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937c3c2621b340faa69b6833001f5efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ed37ceb01249ea81cd653450490307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ad61e54ac64c02bedba29155735b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download the raw model and see what it knows about Swedish meatballs\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "\n",
    "# log this jupyter session in to huggingface\n",
    "huggingface_token = \"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\" # make sure its a 'read' token\n",
    "login(huggingface_token)\n",
    "\n",
    "raw_model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "raw_tokenizer = AutoTokenizer.from_pretrained(raw_model_name)\n",
    "raw_model = AutoModelForCausalLM.from_pretrained(raw_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f93fb828-2a36-4057-a68f-659885e00219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iâ€™m not sure if Iâ€™ve ever had them. Iâ€™ve had meatballs, but I donâ€™t think Iâ€™ve ever had Swedish meatballs.\n",
      "\n",
      "Iâ€™ve had Swedish meatballs. Iâ€™ve had them at Ikea.\n",
      "\n",
      "Iâ€™ve had them at Ikea.\n",
      "\n",
      "Iâ€™ve had them at Ikea.\n",
      "\n",
      "Iâ€™ve had them\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me about Swedish meatballs.\"\n",
    "\n",
    "# Assign the eos_token as the pad_token\n",
    "raw_tokenizer.pad_token = raw_tokenizer.eos_token\n",
    "\n",
    "# Prepare the model inputs with padding and attention mask\n",
    "inputs = raw_tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Extract input IDs and attention mask\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "# Generate output using both input IDs and attention mask\n",
    "output = raw_model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=100)\n",
    "\n",
    "# Decode the response\n",
    "response = raw_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Remove the prompt from the response\n",
    "response_without_prompt = response[len(prompt):].strip()\n",
    "print(response_without_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d4124-6541-427a-b3ea-68da09d598bc",
   "metadata": {
    "id": "d21d4124-6541-427a-b3ea-68da09d598bc"
   },
   "source": [
    "## 3. Download the unsloth Mistral 7B model and prepare for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "F18LfOLGVbym",
   "metadata": {
    "id": "F18LfOLGVbym"
   },
   "outputs": [],
   "source": [
    "model_name = \"unsloth/mistral-7b-instruct-v0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2d9fa60-c2e9-46b7-895c-76391e486f5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2d9fa60-c2e9-46b7-895c-76391e486f5b",
    "outputId": "0397c2a9-0c3c-4490-fa53-320c1cf1a20c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.9: Fast Mistral patching. Transformers = 4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA A10. Max memory: 21.975 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1+cu118. CUDA = 8.6. CUDA Toolkit = 11.8.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = 2048,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a8cac-c6b2-4b46-b093-7558103407a3",
   "metadata": {
    "id": "f41a8cac-c6b2-4b46-b093-7558103407a3"
   },
   "source": [
    "#### Add LoRA adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76d98987-c65d-4681-a6fe-9785cb14df68",
   "metadata": {
    "id": "76d98987-c65d-4681-a6fe-9785cb14df68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.11.9 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    random_state = 1337,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b377d-a004-402e-97fe-760ca72206f7",
   "metadata": {
    "id": "877b377d-a004-402e-97fe-760ca72206f7"
   },
   "source": [
    "## 4. Prepare fine-tuning data\n",
    "\n",
    "Read meatball facts from a file formatted as `domain.jsonl`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e917277-8992-4b00-9a06-ed57835aa42b",
   "metadata": {
    "id": "6e917277-8992-4b00-9a06-ed57835aa42b"
   },
   "outputs": [],
   "source": [
    "jsonl_file = \"domain.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gg9jVHfsVAze",
   "metadata": {
    "id": "gg9jVHfsVAze"
   },
   "source": [
    "Load and reformat the domain data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fDKhMvkiUTqM",
   "metadata": {
    "id": "fDKhMvkiUTqM"
   },
   "outputs": [],
   "source": [
    "# use the dataset loader by Huggingface and some formatting functions\n",
    "dataset = load_dataset(\"json\", data_files=jsonl_file, split=\"train\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def format_text(examples):\n",
    "    texts = [note + tokenizer.pad_token for note in examples[\"text\"]]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "dataset = dataset.map(format_text, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ScQDOp4VaVD",
   "metadata": {
    "id": "0ScQDOp4VaVD"
   },
   "source": [
    "Tokenize the domain data with the pre-trained model's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6lIjxLTbVTbp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "af854e58d42a431fa48535e8e8aa6644",
      "00ca831faf204bcf91fc78a5724cd8e6",
      "9c1aa1daf38e4aeb8d9858929be7ae14",
      "f30bcfdebbcc4391bb45b283ce0b48ce",
      "fff442eb8b5e4dbc9ddcf2f47b5bf414",
      "e51107af09b94c2d85b92ab8109d6af4",
      "1f9191103f414d559285cfed5927f528",
      "92a9b5b25a284609a138d4a9a209b08e",
      "2fb703591d6543ccaff0f98ace7f1e93",
      "a0074981ae6845208ae79c723866466a",
      "2c441204bcc94f10a9bdfc72db3d659d"
     ]
    },
    "id": "6lIjxLTbVTbp",
    "outputId": "77b865f1-0fe8-411b-d569-e9580bdb59a3"
   },
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the text\n",
    "def tokenize_texts(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_texts, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cWJbz5OqV9AE",
   "metadata": {
    "id": "cWJbz5OqV9AE"
   },
   "outputs": [],
   "source": [
    "# Remove unneeded columns and set format for PyTorch\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])  # Keep only tokenized columns\n",
    "tokenized_dataset.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OlT6-2JUYWPT",
   "metadata": {
    "id": "OlT6-2JUYWPT"
   },
   "source": [
    "## 4. Fine-tune the model\n",
    "\n",
    "We want the *training loss* to decrease. A loss value around 2-3 is reasonable, if it gets close to 1.0 or drops below, the predictions will be highly confident, but also with some risk of overfitting, meaning that the model has learned the training data too well and may not perform as effectively on unseen data.\n",
    "\n",
    "*See `README.md` for details about which parameters to tweak to avoid overfitting.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc5a9fa9-18c3-49ec-b0ce-5f45d38bef5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "cc5a9fa9-18c3-49ec-b0ce-5f45d38bef5a",
    "outputId": "eff0558d-4d9d-435a-aced-02d90ad43de4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 500 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 62\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 04:00, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.583100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.837100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.891400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.881900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.752300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.790200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.490900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.686600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.494000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.724500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.433100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.767400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.620300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.527900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.504300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.352700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.340700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.533400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.200900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.298600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.363900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.134000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.400900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.972800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.067200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.967200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.971900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.091900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.332800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.913800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.133800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.973700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.929400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.688000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.748800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.766200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.836500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.834400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.931100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.751200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.941200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.867700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.606700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.748200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.695000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.932800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.454000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.654100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.833700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.803800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>2.049000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    max_seq_length=1024,\n",
    "    dataset_num_proc=2,\n",
    "    packing=False,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate=0.00001, # <<<<<<< THE HIGHER THE RATE THE FASTER TO OVERFIT\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=1,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.3,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=1337,\n",
    "        output_dir=\"outputs\",\n",
    "        report_to=\"none\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0142b-8967-42b0-aa55-ac9e8118d35e",
   "metadata": {},
   "source": [
    "## 5. Save the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b253295d-735b-4f68-a1e9-5e2e3e34e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_for_fine_tuned_model = \"Mistral_MeatBallz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36e44fa3-795b-47c8-a1f5-ca85ea49ba90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mistral_MeatBallz/tokenizer_config.json',\n",
       " 'Mistral_MeatBallz/special_tokens_map.json',\n",
       " 'Mistral_MeatBallz/tokenizer.model',\n",
       " 'Mistral_MeatBallz/added_tokens.json',\n",
       " 'Mistral_MeatBallz/tokenizer.json')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "trainer.model.save_pretrained(name_for_fine_tuned_model)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(name_for_fine_tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5229866-df33-4d00-9005-524ab5e39aec",
   "metadata": {},
   "source": [
    "Now, ask the fine-tuned model about Swedish meatballs..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00ca831faf204bcf91fc78a5724cd8e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e51107af09b94c2d85b92ab8109d6af4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1f9191103f414d559285cfed5927f528",
      "value": "Map:â€‡100%"
     }
    },
    "1f9191103f414d559285cfed5927f528": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c441204bcc94f10a9bdfc72db3d659d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fb703591d6543ccaff0f98ace7f1e93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "92a9b5b25a284609a138d4a9a209b08e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c1aa1daf38e4aeb8d9858929be7ae14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92a9b5b25a284609a138d4a9a209b08e",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fb703591d6543ccaff0f98ace7f1e93",
      "value": 500
     }
    },
    "a0074981ae6845208ae79c723866466a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af854e58d42a431fa48535e8e8aa6644": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_00ca831faf204bcf91fc78a5724cd8e6",
       "IPY_MODEL_9c1aa1daf38e4aeb8d9858929be7ae14",
       "IPY_MODEL_f30bcfdebbcc4391bb45b283ce0b48ce"
      ],
      "layout": "IPY_MODEL_fff442eb8b5e4dbc9ddcf2f47b5bf414"
     }
    },
    "e51107af09b94c2d85b92ab8109d6af4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f30bcfdebbcc4391bb45b283ce0b48ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0074981ae6845208ae79c723866466a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2c441204bcc94f10a9bdfc72db3d659d",
      "value": "â€‡500/500â€‡[00:00&lt;00:00,â€‡2067.96â€‡examples/s]"
     }
    },
    "fff442eb8b5e4dbc9ddcf2f47b5bf414": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
